{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "This notebook demonstrates how to use MARO's reinforcement learning (RL) toolkit to solve the container inventory management ([CIM](https://maro.readthedocs.io/en/latest/scenarios/container_inventory_management.html)) problem. It is formalized as a multi-agent reinforcement learning problem, where each port acts as a decision agent. The agents take actions independently, e.g., loading containers to vessels or discharging containers from vessels.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [State Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "State shaper converts the environment observation to the model input state which includes temporal and spatial information. For this scenario, the model input state includes: \n",
    "\n",
    "- Temporal information, it includes the past week's information of ports and vessels, such as shortage on port and remaining space on vessel. \n",
    "\n",
    "- Spatial information, it includes the related downstream port features.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maro.rl import StateShaper\n",
    "\n",
    "\n",
    "class CIMStateShaper(StateShaper):\n",
    "    def __init__(self, *, look_back, max_ports_downstream, port_attributes, vessel_attributes):\n",
    "        super().__init__()\n",
    "        self._look_back = look_back\n",
    "        self._max_ports_downstream = max_ports_downstream\n",
    "        self._port_attributes = port_attributes\n",
    "        self._vessel_attributes = vessel_attributes\n",
    "        self._dim = (look_back + 1) * (max_ports_downstream + 1) * len(port_attributes) + len(vessel_attributes)\n",
    "\n",
    "    def __call__(self, decision_event, snapshot_list):\n",
    "        tick, port_idx, vessel_idx = decision_event.tick, decision_event.port_idx, decision_event.vessel_idx\n",
    "        ticks = [tick - rt for rt in range(self._look_back-1)]\n",
    "        future_port_idx_list = snapshot_list[\"vessels\"][tick: vessel_idx: 'future_stop_list'].astype('int')\n",
    "        port_features = snapshot_list[\"ports\"][ticks: [port_idx] + list(future_port_idx_list): self._port_attributes]\n",
    "        vessel_features = snapshot_list[\"vessels\"][tick: vessel_idx: self._vessel_attributes]\n",
    "        state = np.concatenate((port_features, vessel_features))\n",
    "        return str(port_idx), state\n",
    "    \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Action Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "Action shaper is used to convert an agent's model output to an environment executable action. For this specific scenario, the output is a discrete index that corresponds to a percentage indicating the fraction of containers to be loaded to or discharged from the arriving vessel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maro.rl import ActionShaper\n",
    "from maro.simulator.scenarios.cim.common import Action\n",
    "\n",
    "\n",
    "class CIMActionShaper(ActionShaper):\n",
    "    def __init__(self, action_space):\n",
    "        super().__init__()\n",
    "        self._action_space = action_space\n",
    "        self._zero_action_index = action_space.index(0)\n",
    "\n",
    "    def __call__(self, model_action, decision_event, snapshot_list):\n",
    "        assert 0 <= model_action < len(self._action_space)\n",
    "        \n",
    "        scope = decision_event.action_scope\n",
    "        tick = decision_event.tick\n",
    "        port_idx = decision_event.port_idx\n",
    "        vessel_idx = decision_event.vessel_idx\n",
    "        port_empty = snapshot_list[\"ports\"][tick: port_idx: [\"empty\", \"full\", \"on_shipper\", \"on_consignee\"]][0]\n",
    "        vessel_remaining_space = snapshot_list[\"vessels\"][tick: vessel_idx: [\"empty\", \"full\", \"remaining_space\"]][2]\n",
    "        early_discharge = snapshot_list[\"vessels\"][tick:vessel_idx: \"early_discharge\"][0]\n",
    "     \n",
    "        if model_action < self._zero_action_index:\n",
    "            # The number of loaded containers must be less thean the vessel's remaining space.\n",
    "            actual_action = max(round(self._action_space[model_action] * port_empty), -vessel_remaining_space)\n",
    "        elif model_action > self._zero_action_index:\n",
    "            # In the case of an early discharge event, we need to subtract the early discharge amount from the expected \n",
    "            # discharge quote.   \n",
    "            plan_action = self._action_space[model_action] * (scope.discharge + early_discharge) - early_discharge\n",
    "            actual_action = round(plan_action) if plan_action > 0 else round(self._action_space[model_action] * scope.discharge)\n",
    "        else:\n",
    "            actual_action = 0\n",
    "\n",
    "        return Action(vessel_idx, port_idx, actual_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Experience Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "Experience shaper is used to convert an episode trajectory to trainable experiences for RL agents. For this specific scenario, the reward is a linear combination of fulfillment and shortage in a limited time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from maro.rl import ExperienceShaper\n",
    "\n",
    "\n",
    "class TruncatedExperienceShaper(ExperienceShaper):\n",
    "    def __init__(self, *, time_window: int, time_decay_factor: float, fulfillment_factor: float,\n",
    "                 shortage_factor: float):\n",
    "        super().__init__(reward_func=None)\n",
    "        self._time_window = time_window\n",
    "        self._time_decay_factor = time_decay_factor\n",
    "        self._fulfillment_factor = fulfillment_factor\n",
    "        self._shortage_factor = shortage_factor\n",
    "\n",
    "    def __call__(self, trajectory, snapshot_list):\n",
    "        experiences_by_agent = {}\n",
    "        for i in range(len(trajectory) - 1):\n",
    "            transition = trajectory[i]\n",
    "            agent_id = transition[\"agent_id\"]\n",
    "            if agent_id not in experiences_by_agent:\n",
    "                experiences_by_agent[agent_id] = defaultdict(list)\n",
    "            \n",
    "            experiences = experiences_by_agent[agent_id]\n",
    "            experiences[\"state\"].append(transition[\"state\"])\n",
    "            experiences[\"action\"].append(transition[\"action\"])\n",
    "            experiences[\"reward\"].append(self._compute_reward(transition[\"event\"], snapshot_list))\n",
    "            experiences[\"next_state\"].append(trajectory[i+1][\"state\"])\n",
    "\n",
    "        return experiences_by_agent\n",
    "\n",
    "    def _compute_reward(self, decision_event, snapshot_list):\n",
    "        start_tick = decision_event.tick + 1\n",
    "        end_tick = decision_event.tick + self._time_window\n",
    "        ticks = list(range(start_tick, end_tick))\n",
    "\n",
    "        # Calculate truncate reward.\n",
    "        future_fulfillment = snapshot_list[\"ports\"][ticks::\"fulfillment\"]\n",
    "        future_shortage = snapshot_list[\"ports\"][ticks::\"shortage\"]\n",
    "        decay_list = [self._time_decay_factor ** i for i in range(end_tick - start_tick)\n",
    "                      for _ in range(future_fulfillment.shape[0]//(end_tick-start_tick))]\n",
    "\n",
    "        tot_fulfillment = np.dot(future_fulfillment, decay_list)\n",
    "        tot_shortage = np.dot(future_shortage, decay_list)\n",
    "\n",
    "        return np.float(self._fulfillment_factor * tot_fulfillment - self._shortage_factor * tot_shortage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Agent](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#agent)\n",
    "\n",
    "For this scenario, the agent is the abstraction of a port. We choose DQN as our underlying learning algorithm with a TD-error-based sampling mechanism.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maro.rl import AbsAgent, ColumnBasedStore\n",
    "\n",
    "\n",
    "class CIMAgent(AbsAgent):\n",
    "    def __init__(self, name, algorithm, experience_pool: ColumnBasedStore, min_experiences_to_train,\n",
    "                 num_batches, batch_size):\n",
    "        super().__init__(name, algorithm, experience_pool)\n",
    "        self._min_experiences_to_train = min_experiences_to_train\n",
    "        self._num_batches = num_batches\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "    def train(self):\n",
    "        if len(self._experience_pool) < self._min_experiences_to_train:\n",
    "            return\n",
    "\n",
    "        for _ in range(self._num_batches):\n",
    "            indexes, sample = self._experience_pool.sample_by_key(\"loss\", self._batch_size)\n",
    "            state = np.asarray(sample[\"state\"])\n",
    "            action = np.asarray(sample[\"action\"])\n",
    "            reward = np.asarray(sample[\"reward\"])\n",
    "            next_state = np.asarray(sample[\"next_state\"])\n",
    "            loss = self._algorithm.train(state, action, reward, next_state)\n",
    "            self._experience_pool.update(indexes, {\"loss\": loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Agent Manager](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#agent-manager)\n",
    "\n",
    "The agent manager inherits from MARO's `AbsAgentManager` which is an agent assembler and isolates the complexities of the environment and algorithm. It will load the DQN algorithm and an experience pool for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import yaml\n",
    "\n",
    "from torch.nn.functional import smooth_l1_loss\n",
    "from torch.optim import RMSprop\n",
    "\n",
    "from maro.rl import AbsAgentManager, LearningModel, MLPDecisionLayers, DQN, DQNHyperParams, ColumnBasedStore\n",
    "\n",
    "\n",
    "num_actions = 21\n",
    "\n",
    "\n",
    "class DQNAgentManager(AbsAgentManager):\n",
    "    def _assemble(self, agent_dict):\n",
    "        for agent_id in self._agent_id_list:\n",
    "            eval_model = LearningModel(decision_layers=MLPDecisionLayers(name=f'{agent_id}.policy',\n",
    "                                                                         input_dim=self._state_shaper.dim,\n",
    "                                                                         output_dim=num_actions,\n",
    "                                                                         hidden_dims=[256, 128, 64],\n",
    "                                                                         dropout_p=.0)\n",
    "                                       )\n",
    "\n",
    "            algorithm = DQN(model_dict={\"eval\": eval_model},\n",
    "                            optimizer_opt=(RMSprop, {\"lr\": 0.05}),\n",
    "                            loss_func_dict={\"eval\": smooth_l1_loss},\n",
    "                            hyper_params=DQNHyperParams(num_actions=num_actions, reward_decay=.0,\n",
    "                                                        num_training_rounds_per_target_replacement=5, tau=0.1)\n",
    "                           )\n",
    "\n",
    "            experience_pool = ColumnBasedStore()\n",
    "            \n",
    "            agent_dict[agent_id] = CIMAgent(name=agent_id, algorithm=algorithm, experience_pool=experience_pool,\n",
    "                                            min_experiences_to_train=1024, num_batches=10, batch_size=128)\n",
    "\n",
    "    def store_experiences(self, experiences):\n",
    "        # The output of the experience shaper is organized by the agent ID.   \n",
    "        for agent_id, exp in experiences.items():\n",
    "            exp.update({\"loss\": [1e8] * len(exp[next(iter(exp))])})\n",
    "            self._agent_dict[agent_id].store_experiences(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop with [Actor and Learner](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#learner-and-actor)\n",
    "\n",
    "This code cell demonstrates the typical workflow of a learning policy's interaction with a MARO environment. \n",
    "\n",
    "- Initialize an environment with specific scenario and topology parameters. \n",
    "\n",
    "- Define scenario-specific components, e.g. shapers. \n",
    "\n",
    "- Create an agent manager, which assembles underlying agents. \n",
    "\n",
    "- Create an actor and a learner to start the training process in which the agent manager interacts with the environment for collecting experiences and updating policies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:42:49 | single_host_cim_learner | INFO | ep 1 - performance: {'order_requirements': 2240000, 'container_shortage': 1471903, 'operation_number': 2998694}, epsilons: {'0': 0.4, '1': 0.4, '2': 0.4, '3': 0.4}\n",
      "10:42:53 | single_host_cim_learner | INFO | ep 2 - performance: {'order_requirements': 2240000, 'container_shortage': 1749783, 'operation_number': 2682255}, epsilons: {'0': 0.39836734693877884, '1': 0.39836734693877884, '2': 0.39836734693877884, '3': 0.39836734693877884}\n",
      "10:42:57 | single_host_cim_learner | INFO | ep 3 - performance: {'order_requirements': 2240000, 'container_shortage': 1602611, 'operation_number': 2882583}, epsilons: {'0': 0.39673469387755766, '1': 0.39673469387755766, '2': 0.39673469387755766, '3': 0.39673469387755766}\n",
      "10:43:01 | single_host_cim_learner | INFO | ep 4 - performance: {'order_requirements': 2240000, 'container_shortage': 1685691, 'operation_number': 2560449}, epsilons: {'0': 0.3951020408163365, '1': 0.3951020408163365, '2': 0.3951020408163365, '3': 0.3951020408163365}\n",
      "10:43:06 | single_host_cim_learner | INFO | ep 5 - performance: {'order_requirements': 2240000, 'container_shortage': 1642661, 'operation_number': 3391669}, epsilons: {'0': 0.3934693877551153, '1': 0.3934693877551153, '2': 0.3934693877551153, '3': 0.3934693877551153}\n",
      "10:43:10 | single_host_cim_learner | INFO | ep 6 - performance: {'order_requirements': 2240000, 'container_shortage': 1417467, 'operation_number': 3304565}, epsilons: {'0': 0.39183673469389413, '1': 0.39183673469389413, '2': 0.39183673469389413, '3': 0.39183673469389413}\n",
      "10:43:14 | single_host_cim_learner | INFO | ep 7 - performance: {'order_requirements': 2240000, 'container_shortage': 1334117, 'operation_number': 3217649}, epsilons: {'0': 0.39020408163267295, '1': 0.39020408163267295, '2': 0.39020408163267295, '3': 0.39020408163267295}\n",
      "10:43:19 | single_host_cim_learner | INFO | ep 8 - performance: {'order_requirements': 2240000, 'container_shortage': 1970188, 'operation_number': 2342474}, epsilons: {'0': 0.38857142857145177, '1': 0.38857142857145177, '2': 0.38857142857145177, '3': 0.38857142857145177}\n",
      "10:43:24 | single_host_cim_learner | INFO | ep 9 - performance: {'order_requirements': 2240000, 'container_shortage': 921116, 'operation_number': 3455650}, epsilons: {'0': 0.3869387755102306, '1': 0.3869387755102306, '2': 0.3869387755102306, '3': 0.3869387755102306}\n",
      "10:43:29 | single_host_cim_learner | INFO | ep 10 - performance: {'order_requirements': 2240000, 'container_shortage': 1214701, 'operation_number': 2963197}, epsilons: {'0': 0.3853061224490094, '1': 0.3853061224490094, '2': 0.3853061224490094, '3': 0.3853061224490094}\n",
      "10:43:33 | single_host_cim_learner | INFO | ep 11 - performance: {'order_requirements': 2240000, 'container_shortage': 1400335, 'operation_number': 3407082}, epsilons: {'0': 0.38367346938778824, '1': 0.38367346938778824, '2': 0.38367346938778824, '3': 0.38367346938778824}\n",
      "10:43:38 | single_host_cim_learner | INFO | ep 12 - performance: {'order_requirements': 2240000, 'container_shortage': 728902, 'operation_number': 3688912}, epsilons: {'0': 0.38204081632656706, '1': 0.38204081632656706, '2': 0.38204081632656706, '3': 0.38204081632656706}\n",
      "10:43:43 | single_host_cim_learner | INFO | ep 13 - performance: {'order_requirements': 2240000, 'container_shortage': 899359, 'operation_number': 4382531}, epsilons: {'0': 0.3804081632653459, '1': 0.3804081632653459, '2': 0.3804081632653459, '3': 0.3804081632653459}\n",
      "10:43:47 | single_host_cim_learner | INFO | ep 14 - performance: {'order_requirements': 2240000, 'container_shortage': 961579, 'operation_number': 4486164}, epsilons: {'0': 0.3787755102041247, '1': 0.3787755102041247, '2': 0.3787755102041247, '3': 0.3787755102041247}\n",
      "10:43:52 | single_host_cim_learner | INFO | ep 15 - performance: {'order_requirements': 2240000, 'container_shortage': 831690, 'operation_number': 4283354}, epsilons: {'0': 0.3771428571429035, '1': 0.3771428571429035, '2': 0.3771428571429035, '3': 0.3771428571429035}\n",
      "10:43:56 | single_host_cim_learner | INFO | ep 16 - performance: {'order_requirements': 2240000, 'container_shortage': 996019, 'operation_number': 4626933}, epsilons: {'0': 0.37551020408168234, '1': 0.37551020408168234, '2': 0.37551020408168234, '3': 0.37551020408168234}\n",
      "10:44:01 | single_host_cim_learner | INFO | ep 17 - performance: {'order_requirements': 2240000, 'container_shortage': 747960, 'operation_number': 3693008}, epsilons: {'0': 0.37387755102046116, '1': 0.37387755102046116, '2': 0.37387755102046116, '3': 0.37387755102046116}\n",
      "10:44:06 | single_host_cim_learner | INFO | ep 18 - performance: {'order_requirements': 2240000, 'container_shortage': 693959, 'operation_number': 3760747}, epsilons: {'0': 0.37224489795924, '1': 0.37224489795924, '2': 0.37224489795924, '3': 0.37224489795924}\n",
      "10:44:10 | single_host_cim_learner | INFO | ep 19 - performance: {'order_requirements': 2240000, 'container_shortage': 708174, 'operation_number': 3817824}, epsilons: {'0': 0.3706122448980188, '1': 0.3706122448980188, '2': 0.3706122448980188, '3': 0.3706122448980188}\n",
      "10:44:15 | single_host_cim_learner | INFO | ep 20 - performance: {'order_requirements': 2240000, 'container_shortage': 877014, 'operation_number': 3850338}, epsilons: {'0': 0.3689795918367976, '1': 0.3689795918367976, '2': 0.3689795918367976, '3': 0.3689795918367976}\n",
      "10:44:19 | single_host_cim_learner | INFO | ep 21 - performance: {'order_requirements': 2240000, 'container_shortage': 737060, 'operation_number': 3896340}, epsilons: {'0': 0.36734693877557645, '1': 0.36734693877557645, '2': 0.36734693877557645, '3': 0.36734693877557645}\n",
      "10:44:24 | single_host_cim_learner | INFO | ep 22 - performance: {'order_requirements': 2240000, 'container_shortage': 779835, 'operation_number': 4066950}, epsilons: {'0': 0.36571428571435527, '1': 0.36571428571435527, '2': 0.36571428571435527, '3': 0.36571428571435527}\n",
      "10:44:29 | single_host_cim_learner | INFO | ep 23 - performance: {'order_requirements': 2240000, 'container_shortage': 739221, 'operation_number': 3852759}, epsilons: {'0': 0.3640816326531341, '1': 0.3640816326531341, '2': 0.3640816326531341, '3': 0.3640816326531341}\n",
      "10:44:33 | single_host_cim_learner | INFO | ep 24 - performance: {'order_requirements': 2240000, 'container_shortage': 599721, 'operation_number': 3997403}, epsilons: {'0': 0.3624489795919129, '1': 0.3624489795919129, '2': 0.3624489795919129, '3': 0.3624489795919129}\n",
      "10:44:38 | single_host_cim_learner | INFO | ep 25 - performance: {'order_requirements': 2240000, 'container_shortage': 781556, 'operation_number': 4142961}, epsilons: {'0': 0.36081632653069173, '1': 0.36081632653069173, '2': 0.36081632653069173, '3': 0.36081632653069173}\n",
      "10:44:43 | single_host_cim_learner | INFO | ep 26 - performance: {'order_requirements': 2240000, 'container_shortage': 735564, 'operation_number': 3897327}, epsilons: {'0': 0.35918367346947055, '1': 0.35918367346947055, '2': 0.35918367346947055, '3': 0.35918367346947055}\n",
      "10:44:48 | single_host_cim_learner | INFO | ep 27 - performance: {'order_requirements': 2240000, 'container_shortage': 806261, 'operation_number': 4010914}, epsilons: {'0': 0.3575510204082494, '1': 0.3575510204082494, '2': 0.3575510204082494, '3': 0.3575510204082494}\n",
      "10:44:52 | single_host_cim_learner | INFO | ep 28 - performance: {'order_requirements': 2240000, 'container_shortage': 601312, 'operation_number': 4292785}, epsilons: {'0': 0.3559183673470282, '1': 0.3559183673470282, '2': 0.3559183673470282, '3': 0.3559183673470282}\n",
      "10:44:57 | single_host_cim_learner | INFO | ep 29 - performance: {'order_requirements': 2240000, 'container_shortage': 559083, 'operation_number': 4170095}, epsilons: {'0': 0.354285714285807, '1': 0.354285714285807, '2': 0.354285714285807, '3': 0.354285714285807}\n",
      "10:45:02 | single_host_cim_learner | INFO | ep 30 - performance: {'order_requirements': 2240000, 'container_shortage': 504573, 'operation_number': 4163412}, epsilons: {'0': 0.35265306122458584, '1': 0.35265306122458584, '2': 0.35265306122458584, '3': 0.35265306122458584}\n",
      "10:45:07 | single_host_cim_learner | INFO | ep 31 - performance: {'order_requirements': 2240000, 'container_shortage': 851783, 'operation_number': 4303632}, epsilons: {'0': 0.35102040816336466, '1': 0.35102040816336466, '2': 0.35102040816336466, '3': 0.35102040816336466}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:45:12 | single_host_cim_learner | INFO | ep 32 - performance: {'order_requirements': 2240000, 'container_shortage': 538322, 'operation_number': 3954792}, epsilons: {'0': 0.3493877551021435, '1': 0.3493877551021435, '2': 0.3493877551021435, '3': 0.3493877551021435}\n",
      "10:45:16 | single_host_cim_learner | INFO | ep 33 - performance: {'order_requirements': 2240000, 'container_shortage': 622649, 'operation_number': 4035090}, epsilons: {'0': 0.3477551020409223, '1': 0.3477551020409223, '2': 0.3477551020409223, '3': 0.3477551020409223}\n",
      "10:45:21 | single_host_cim_learner | INFO | ep 34 - performance: {'order_requirements': 2240000, 'container_shortage': 706875, 'operation_number': 3731018}, epsilons: {'0': 0.3461224489797011, '1': 0.3461224489797011, '2': 0.3461224489797011, '3': 0.3461224489797011}\n",
      "10:45:26 | single_host_cim_learner | INFO | ep 35 - performance: {'order_requirements': 2240000, 'container_shortage': 476805, 'operation_number': 4059672}, epsilons: {'0': 0.34448979591847995, '1': 0.34448979591847995, '2': 0.34448979591847995, '3': 0.34448979591847995}\n",
      "10:45:30 | single_host_cim_learner | INFO | ep 36 - performance: {'order_requirements': 2240000, 'container_shortage': 792619, 'operation_number': 3501539}, epsilons: {'0': 0.34285714285725877, '1': 0.34285714285725877, '2': 0.34285714285725877, '3': 0.34285714285725877}\n",
      "10:45:35 | single_host_cim_learner | INFO | ep 37 - performance: {'order_requirements': 2240000, 'container_shortage': 508840, 'operation_number': 4132005}, epsilons: {'0': 0.3412244897960376, '1': 0.3412244897960376, '2': 0.3412244897960376, '3': 0.3412244897960376}\n",
      "10:45:40 | single_host_cim_learner | INFO | ep 38 - performance: {'order_requirements': 2240000, 'container_shortage': 632638, 'operation_number': 3917010}, epsilons: {'0': 0.3395918367348164, '1': 0.3395918367348164, '2': 0.3395918367348164, '3': 0.3395918367348164}\n",
      "10:45:45 | single_host_cim_learner | INFO | ep 39 - performance: {'order_requirements': 2240000, 'container_shortage': 558274, 'operation_number': 4168704}, epsilons: {'0': 0.33795918367359523, '1': 0.33795918367359523, '2': 0.33795918367359523, '3': 0.33795918367359523}\n",
      "10:45:50 | single_host_cim_learner | INFO | ep 40 - performance: {'order_requirements': 2240000, 'container_shortage': 574387, 'operation_number': 4589579}, epsilons: {'0': 0.33632653061237405, '1': 0.33632653061237405, '2': 0.33632653061237405, '3': 0.33632653061237405}\n",
      "10:45:55 | single_host_cim_learner | INFO | ep 41 - performance: {'order_requirements': 2240000, 'container_shortage': 514229, 'operation_number': 4196751}, epsilons: {'0': 0.3346938775511529, '1': 0.3346938775511529, '2': 0.3346938775511529, '3': 0.3346938775511529}\n",
      "10:45:59 | single_host_cim_learner | INFO | ep 42 - performance: {'order_requirements': 2240000, 'container_shortage': 546013, 'operation_number': 4070179}, epsilons: {'0': 0.3330612244899317, '1': 0.3330612244899317, '2': 0.3330612244899317, '3': 0.3330612244899317}\n",
      "10:46:04 | single_host_cim_learner | INFO | ep 43 - performance: {'order_requirements': 2240000, 'container_shortage': 566994, 'operation_number': 4073685}, epsilons: {'0': 0.3314285714287105, '1': 0.3314285714287105, '2': 0.3314285714287105, '3': 0.3314285714287105}\n",
      "10:46:09 | single_host_cim_learner | INFO | ep 44 - performance: {'order_requirements': 2240000, 'container_shortage': 603963, 'operation_number': 4005202}, epsilons: {'0': 0.32979591836748934, '1': 0.32979591836748934, '2': 0.32979591836748934, '3': 0.32979591836748934}\n",
      "10:46:13 | single_host_cim_learner | INFO | ep 45 - performance: {'order_requirements': 2240000, 'container_shortage': 404557, 'operation_number': 4628756}, epsilons: {'0': 0.32816326530626816, '1': 0.32816326530626816, '2': 0.32816326530626816, '3': 0.32816326530626816}\n",
      "10:46:18 | single_host_cim_learner | INFO | ep 46 - performance: {'order_requirements': 2240000, 'container_shortage': 459178, 'operation_number': 4251896}, epsilons: {'0': 0.326530612245047, '1': 0.326530612245047, '2': 0.326530612245047, '3': 0.326530612245047}\n",
      "10:46:23 | single_host_cim_learner | INFO | ep 47 - performance: {'order_requirements': 2240000, 'container_shortage': 680686, 'operation_number': 4587090}, epsilons: {'0': 0.3248979591838258, '1': 0.3248979591838258, '2': 0.3248979591838258, '3': 0.3248979591838258}\n",
      "10:46:28 | single_host_cim_learner | INFO | ep 48 - performance: {'order_requirements': 2240000, 'container_shortage': 431512, 'operation_number': 4108741}, epsilons: {'0': 0.3232653061226046, '1': 0.3232653061226046, '2': 0.3232653061226046, '3': 0.3232653061226046}\n",
      "10:46:32 | single_host_cim_learner | INFO | ep 49 - performance: {'order_requirements': 2240000, 'container_shortage': 551913, 'operation_number': 4381044}, epsilons: {'0': 0.32163265306138344, '1': 0.32163265306138344, '2': 0.32163265306138344, '3': 0.32163265306138344}\n",
      "10:46:37 | single_host_cim_learner | INFO | ep 50 - performance: {'order_requirements': 2240000, 'container_shortage': 731294, 'operation_number': 4311078}, epsilons: {'0': 0.32000000000016227, '1': 0.32000000000016227, '2': 0.32000000000016227, '3': 0.32000000000016227}\n",
      "10:46:42 | single_host_cim_learner | INFO | ep 51 - performance: {'order_requirements': 2240000, 'container_shortage': 643775, 'operation_number': 3956599}, epsilons: {'0': 0.3183673469389411, '1': 0.3183673469389411, '2': 0.3183673469389411, '3': 0.3183673469389411}\n",
      "10:46:47 | single_host_cim_learner | INFO | ep 52 - performance: {'order_requirements': 2240000, 'container_shortage': 520778, 'operation_number': 4270831}, epsilons: {'0': 0.3119673469389539, '1': 0.3119673469389539, '2': 0.3119673469389539, '3': 0.3119673469389539}\n",
      "10:46:51 | single_host_cim_learner | INFO | ep 53 - performance: {'order_requirements': 2240000, 'container_shortage': 424125, 'operation_number': 4409254}, epsilons: {'0': 0.3055673469389667, '1': 0.3055673469389667, '2': 0.3055673469389667, '3': 0.3055673469389667}\n",
      "10:46:56 | single_host_cim_learner | INFO | ep 54 - performance: {'order_requirements': 2240000, 'container_shortage': 626297, 'operation_number': 4028701}, epsilons: {'0': 0.2991673469389795, '1': 0.2991673469389795, '2': 0.2991673469389795, '3': 0.2991673469389795}\n",
      "10:47:01 | single_host_cim_learner | INFO | ep 55 - performance: {'order_requirements': 2240000, 'container_shortage': 380644, 'operation_number': 4520496}, epsilons: {'0': 0.2927673469389923, '1': 0.2927673469389923, '2': 0.2927673469389923, '3': 0.2927673469389923}\n",
      "10:47:06 | single_host_cim_learner | INFO | ep 56 - performance: {'order_requirements': 2240000, 'container_shortage': 301492, 'operation_number': 4504974}, epsilons: {'0': 0.2863673469390051, '1': 0.2863673469390051, '2': 0.2863673469390051, '3': 0.2863673469390051}\n",
      "10:47:11 | single_host_cim_learner | INFO | ep 57 - performance: {'order_requirements': 2240000, 'container_shortage': 480587, 'operation_number': 4638024}, epsilons: {'0': 0.2799673469390179, '1': 0.2799673469390179, '2': 0.2799673469390179, '3': 0.2799673469390179}\n",
      "10:47:16 | single_host_cim_learner | INFO | ep 58 - performance: {'order_requirements': 2240000, 'container_shortage': 279138, 'operation_number': 4420042}, epsilons: {'0': 0.27356734693903073, '1': 0.27356734693903073, '2': 0.27356734693903073, '3': 0.27356734693903073}\n",
      "10:47:21 | single_host_cim_learner | INFO | ep 59 - performance: {'order_requirements': 2240000, 'container_shortage': 309761, 'operation_number': 4384082}, epsilons: {'0': 0.26716734693904354, '1': 0.26716734693904354, '2': 0.26716734693904354, '3': 0.26716734693904354}\n",
      "10:47:25 | single_host_cim_learner | INFO | ep 60 - performance: {'order_requirements': 2240000, 'container_shortage': 232598, 'operation_number': 4498145}, epsilons: {'0': 0.26076734693905634, '1': 0.26076734693905634, '2': 0.26076734693905634, '3': 0.26076734693905634}\n",
      "10:47:30 | single_host_cim_learner | INFO | ep 61 - performance: {'order_requirements': 2240000, 'container_shortage': 364515, 'operation_number': 4578089}, epsilons: {'0': 0.25436734693906915, '1': 0.25436734693906915, '2': 0.25436734693906915, '3': 0.25436734693906915}\n",
      "10:47:35 | single_host_cim_learner | INFO | ep 62 - performance: {'order_requirements': 2240000, 'container_shortage': 276436, 'operation_number': 4315130}, epsilons: {'0': 0.24796734693908196, '1': 0.24796734693908196, '2': 0.24796734693908196, '3': 0.24796734693908196}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:47:40 | single_host_cim_learner | INFO | ep 63 - performance: {'order_requirements': 2240000, 'container_shortage': 377861, 'operation_number': 4280589}, epsilons: {'0': 0.24156734693909476, '1': 0.24156734693909476, '2': 0.24156734693909476, '3': 0.24156734693909476}\n",
      "10:47:45 | single_host_cim_learner | INFO | ep 64 - performance: {'order_requirements': 2240000, 'container_shortage': 256642, 'operation_number': 4542020}, epsilons: {'0': 0.23516734693910757, '1': 0.23516734693910757, '2': 0.23516734693910757, '3': 0.23516734693910757}\n",
      "10:47:50 | single_host_cim_learner | INFO | ep 65 - performance: {'order_requirements': 2240000, 'container_shortage': 246418, 'operation_number': 4533773}, epsilons: {'0': 0.22876734693912038, '1': 0.22876734693912038, '2': 0.22876734693912038, '3': 0.22876734693912038}\n",
      "10:47:55 | single_host_cim_learner | INFO | ep 66 - performance: {'order_requirements': 2240000, 'container_shortage': 251040, 'operation_number': 4303025}, epsilons: {'0': 0.22236734693913318, '1': 0.22236734693913318, '2': 0.22236734693913318, '3': 0.22236734693913318}\n",
      "10:48:00 | single_host_cim_learner | INFO | ep 67 - performance: {'order_requirements': 2240000, 'container_shortage': 333194, 'operation_number': 4391156}, epsilons: {'0': 0.215967346939146, '1': 0.215967346939146, '2': 0.215967346939146, '3': 0.215967346939146}\n",
      "10:48:05 | single_host_cim_learner | INFO | ep 68 - performance: {'order_requirements': 2240000, 'container_shortage': 316087, 'operation_number': 4189109}, epsilons: {'0': 0.2095673469391588, '1': 0.2095673469391588, '2': 0.2095673469391588, '3': 0.2095673469391588}\n",
      "10:48:10 | single_host_cim_learner | INFO | ep 69 - performance: {'order_requirements': 2240000, 'container_shortage': 338686, 'operation_number': 4063866}, epsilons: {'0': 0.2031673469391716, '1': 0.2031673469391716, '2': 0.2031673469391716, '3': 0.2031673469391716}\n",
      "10:48:15 | single_host_cim_learner | INFO | ep 70 - performance: {'order_requirements': 2240000, 'container_shortage': 239006, 'operation_number': 4512630}, epsilons: {'0': 0.1967673469391844, '1': 0.1967673469391844, '2': 0.1967673469391844, '3': 0.1967673469391844}\n",
      "10:48:20 | single_host_cim_learner | INFO | ep 71 - performance: {'order_requirements': 2240000, 'container_shortage': 239085, 'operation_number': 4375504}, epsilons: {'0': 0.1903673469391972, '1': 0.1903673469391972, '2': 0.1903673469391972, '3': 0.1903673469391972}\n",
      "10:48:25 | single_host_cim_learner | INFO | ep 72 - performance: {'order_requirements': 2240000, 'container_shortage': 213239, 'operation_number': 4399888}, epsilons: {'0': 0.18396734693921002, '1': 0.18396734693921002, '2': 0.18396734693921002, '3': 0.18396734693921002}\n",
      "10:48:30 | single_host_cim_learner | INFO | ep 73 - performance: {'order_requirements': 2240000, 'container_shortage': 427995, 'operation_number': 4177450}, epsilons: {'0': 0.17756734693922283, '1': 0.17756734693922283, '2': 0.17756734693922283, '3': 0.17756734693922283}\n",
      "10:48:35 | single_host_cim_learner | INFO | ep 74 - performance: {'order_requirements': 2240000, 'container_shortage': 585601, 'operation_number': 3969371}, epsilons: {'0': 0.17116734693923563, '1': 0.17116734693923563, '2': 0.17116734693923563, '3': 0.17116734693923563}\n",
      "10:48:40 | single_host_cim_learner | INFO | ep 75 - performance: {'order_requirements': 2240000, 'container_shortage': 326819, 'operation_number': 4122134}, epsilons: {'0': 0.16476734693924844, '1': 0.16476734693924844, '2': 0.16476734693924844, '3': 0.16476734693924844}\n",
      "10:48:45 | single_host_cim_learner | INFO | ep 76 - performance: {'order_requirements': 2240000, 'container_shortage': 148429, 'operation_number': 4367860}, epsilons: {'0': 0.15836734693926124, '1': 0.15836734693926124, '2': 0.15836734693926124, '3': 0.15836734693926124}\n",
      "10:48:50 | single_host_cim_learner | INFO | ep 77 - performance: {'order_requirements': 2240000, 'container_shortage': 207352, 'operation_number': 4388219}, epsilons: {'0': 0.15196734693927405, '1': 0.15196734693927405, '2': 0.15196734693927405, '3': 0.15196734693927405}\n",
      "10:48:55 | single_host_cim_learner | INFO | ep 78 - performance: {'order_requirements': 2240000, 'container_shortage': 260726, 'operation_number': 4301982}, epsilons: {'0': 0.14556734693928686, '1': 0.14556734693928686, '2': 0.14556734693928686, '3': 0.14556734693928686}\n",
      "10:49:00 | single_host_cim_learner | INFO | ep 79 - performance: {'order_requirements': 2240000, 'container_shortage': 129180, 'operation_number': 4560744}, epsilons: {'0': 0.13916734693929966, '1': 0.13916734693929966, '2': 0.13916734693929966, '3': 0.13916734693929966}\n",
      "10:49:05 | single_host_cim_learner | INFO | ep 80 - performance: {'order_requirements': 2240000, 'container_shortage': 60834, 'operation_number': 4562955}, epsilons: {'0': 0.13276734693931247, '1': 0.13276734693931247, '2': 0.13276734693931247, '3': 0.13276734693931247}\n",
      "10:49:10 | single_host_cim_learner | INFO | ep 81 - performance: {'order_requirements': 2240000, 'container_shortage': 90745, 'operation_number': 4433685}, epsilons: {'0': 0.12636734693932528, '1': 0.12636734693932528, '2': 0.12636734693932528, '3': 0.12636734693932528}\n",
      "10:49:15 | single_host_cim_learner | INFO | ep 82 - performance: {'order_requirements': 2240000, 'container_shortage': 196778, 'operation_number': 4264127}, epsilons: {'0': 0.11996734693933808, '1': 0.11996734693933808, '2': 0.11996734693933808, '3': 0.11996734693933808}\n",
      "10:49:20 | single_host_cim_learner | INFO | ep 83 - performance: {'order_requirements': 2240000, 'container_shortage': 174344, 'operation_number': 4506476}, epsilons: {'0': 0.11356734693935089, '1': 0.11356734693935089, '2': 0.11356734693935089, '3': 0.11356734693935089}\n",
      "10:49:25 | single_host_cim_learner | INFO | ep 84 - performance: {'order_requirements': 2240000, 'container_shortage': 163431, 'operation_number': 4402926}, epsilons: {'0': 0.1071673469393637, '1': 0.1071673469393637, '2': 0.1071673469393637, '3': 0.1071673469393637}\n",
      "10:49:29 | single_host_cim_learner | INFO | ep 85 - performance: {'order_requirements': 2240000, 'container_shortage': 359664, 'operation_number': 3931534}, epsilons: {'0': 0.1007673469393765, '1': 0.1007673469393765, '2': 0.1007673469393765, '3': 0.1007673469393765}\n",
      "10:49:34 | single_host_cim_learner | INFO | ep 86 - performance: {'order_requirements': 2240000, 'container_shortage': 105613, 'operation_number': 4407328}, epsilons: {'0': 0.09436734693938931, '1': 0.09436734693938931, '2': 0.09436734693938931, '3': 0.09436734693938931}\n",
      "10:49:39 | single_host_cim_learner | INFO | ep 87 - performance: {'order_requirements': 2240000, 'container_shortage': 518503, 'operation_number': 3770252}, epsilons: {'0': 0.08796734693940211, '1': 0.08796734693940211, '2': 0.08796734693940211, '3': 0.08796734693940211}\n",
      "10:49:44 | single_host_cim_learner | INFO | ep 88 - performance: {'order_requirements': 2240000, 'container_shortage': 272846, 'operation_number': 4075937}, epsilons: {'0': 0.08156734693941492, '1': 0.08156734693941492, '2': 0.08156734693941492, '3': 0.08156734693941492}\n",
      "10:49:49 | single_host_cim_learner | INFO | ep 89 - performance: {'order_requirements': 2240000, 'container_shortage': 302339, 'operation_number': 4011795}, epsilons: {'0': 0.07516734693942773, '1': 0.07516734693942773, '2': 0.07516734693942773, '3': 0.07516734693942773}\n",
      "10:49:54 | single_host_cim_learner | INFO | ep 90 - performance: {'order_requirements': 2240000, 'container_shortage': 184906, 'operation_number': 4262003}, epsilons: {'0': 0.06876734693944053, '1': 0.06876734693944053, '2': 0.06876734693944053, '3': 0.06876734693944053}\n",
      "10:49:59 | single_host_cim_learner | INFO | ep 91 - performance: {'order_requirements': 2240000, 'container_shortage': 316880, 'operation_number': 3925505}, epsilons: {'0': 0.06236734693945333, '1': 0.06236734693945333, '2': 0.06236734693945333, '3': 0.06236734693945333}\n",
      "10:50:04 | single_host_cim_learner | INFO | ep 92 - performance: {'order_requirements': 2240000, 'container_shortage': 182421, 'operation_number': 4191916}, epsilons: {'0': 0.05596734693946613, '1': 0.05596734693946613, '2': 0.05596734693946613, '3': 0.05596734693946613}\n",
      "10:50:09 | single_host_cim_learner | INFO | ep 93 - performance: {'order_requirements': 2240000, 'container_shortage': 87904, 'operation_number': 4366189}, epsilons: {'0': 0.04956734693947893, '1': 0.04956734693947893, '2': 0.04956734693947893, '3': 0.04956734693947893}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:50:15 | single_host_cim_learner | INFO | ep 94 - performance: {'order_requirements': 2240000, 'container_shortage': 288975, 'operation_number': 3916529}, epsilons: {'0': 0.04316734693949173, '1': 0.04316734693949173, '2': 0.04316734693949173, '3': 0.04316734693949173}\n",
      "10:50:20 | single_host_cim_learner | INFO | ep 95 - performance: {'order_requirements': 2240000, 'container_shortage': 259727, 'operation_number': 4057942}, epsilons: {'0': 0.03676734693950453, '1': 0.03676734693950453, '2': 0.03676734693950453, '3': 0.03676734693950453}\n",
      "10:50:25 | single_host_cim_learner | INFO | ep 96 - performance: {'order_requirements': 2240000, 'container_shortage': 284335, 'operation_number': 3962831}, epsilons: {'0': 0.03036734693951733, '1': 0.03036734693951733, '2': 0.03036734693951733, '3': 0.03036734693951733}\n",
      "10:50:30 | single_host_cim_learner | INFO | ep 97 - performance: {'order_requirements': 2240000, 'container_shortage': 55845, 'operation_number': 4383305}, epsilons: {'0': 0.023967346939530128, '1': 0.023967346939530128, '2': 0.023967346939530128, '3': 0.023967346939530128}\n",
      "10:50:35 | single_host_cim_learner | INFO | ep 98 - performance: {'order_requirements': 2240000, 'container_shortage': 252218, 'operation_number': 4007054}, epsilons: {'0': 0.017567346939542927, '1': 0.017567346939542927, '2': 0.017567346939542927, '3': 0.017567346939542927}\n",
      "10:50:40 | single_host_cim_learner | INFO | ep 99 - performance: {'order_requirements': 2240000, 'container_shortage': 45084, 'operation_number': 4339789}, epsilons: {'0': 0.011167346939555726, '1': 0.011167346939555726, '2': 0.011167346939555726, '3': 0.011167346939555726}\n",
      "10:50:45 | single_host_cim_learner | INFO | ep 100 - performance: {'order_requirements': 2240000, 'container_shortage': 265096, 'operation_number': 3919248}, epsilons: {'0': 0.004767346939568526, '1': 0.004767346939568526, '2': 0.004767346939568526, '3': 0.004767346939568526}\n"
     ]
    }
   ],
   "source": [
    "from maro.simulator import Env\n",
    "from maro.rl import SimpleLearner, SimpleActor, AgentMode, TwoPhaseLinearExplorer\n",
    "from maro.utils import Logger, LogFormat\n",
    "\n",
    "# Step 1: initialize a CIM environment for using a toy dataset. \n",
    "env = Env(\"cim\", \"toy.4p_ssdd_l0.0\", durations=1120)\n",
    "total_episodes = 100\n",
    "agent_id_list = [str(agent_id) for agent_id in env.agent_idx_list]\n",
    "\n",
    "# Step 2: create state, action and experience shapers. We also need to create an explorer here due to the \n",
    "# greedy nature of the DQN algorithm.  \n",
    "state_shaper = CIMStateShaper(look_back=7, max_ports_downstream=2, \n",
    "                              port_attributes=[\"empty\", \"full\", \"on_shipper\", \"on_consignee\", \n",
    "                                               \"booking\", \"shortage\", \"fulfillment\"],\n",
    "                              vessel_attributes=[\"empty\", \"full\", \"remaining_space\"]\n",
    "                             )\n",
    "\n",
    "action_shaper = CIMActionShaper(action_space=list(np.linspace(-1.0, 1.0, num_actions)))\n",
    "\n",
    "experience_shaper = TruncatedExperienceShaper(time_window=100, fulfillment_factor=1.0, shortage_factor=1.0,\n",
    "                                              time_decay_factor=0.97)\n",
    "\n",
    "explorer = TwoPhaseLinearExplorer(agent_id_list, total_episodes, \n",
    "                                  epsilon_range_dict={\"_all_\": (.0, .4)},\n",
    "                                  split_point_dict={\"_all_\": (.5, .8)},\n",
    "                                  with_cache=True)\n",
    "\n",
    "# Step 3: create an agent manager.\n",
    "agent_manager = DQNAgentManager(name=\"cim_learner\",\n",
    "                                mode=AgentMode.TRAIN_INFERENCE,\n",
    "                                agent_id_list=agent_id_list,\n",
    "                                state_shaper=state_shaper,\n",
    "                                action_shaper=action_shaper,\n",
    "                                experience_shaper=experience_shaper,\n",
    "                                explorer=explorer)\n",
    "\n",
    "# Step 4: Create an actor and a learner to start the training process. \n",
    "actor = SimpleActor(env, agent_manager)\n",
    "learner = SimpleLearner(trainable_agents=agent_manager, actor=actor,\n",
    "                        logger=Logger(\"single_host_cim_learner\", format_=LogFormat.simple, auto_timestamp=False))\n",
    "\n",
    "learner.train(total_episodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
