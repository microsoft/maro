{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "This notebook demonstrates how to use MARO's reinforcement learning (RL) toolkit to solve the container inventory management ([CIM](https://maro.readthedocs.io/en/latest/scenarios/container_inventory_management.html)) problem. It is formalized as a multi-agent reinforcement learning problem, where each port acts as a decision agent. The agents take actions independently, e.g., loading containers to vessels or discharging containers from vessels.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [State Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "State shaper converts the environment observation to the model input state which includes temporal and spatial information. For this scenario, the model input state includes: \n",
    "\n",
    "- Temporal information, including the past week's information of ports and vessels, such as shortage on port and remaining space on vessel. \n",
    "\n",
    "- Spatial information, it including the related downstream port features.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maro.rl import StateShaper\n",
    "\n",
    "\n",
    "class CIMStateShaper(StateShaper):\n",
    "    def __init__(self, *, look_back, max_ports_downstream, port_attributes, vessel_attributes):\n",
    "        super().__init__()\n",
    "        self._look_back = look_back\n",
    "        self._max_ports_downstream = max_ports_downstream\n",
    "        self._port_attributes = port_attributes\n",
    "        self._vessel_attributes = vessel_attributes\n",
    "        self._dim = (look_back + 1) * (max_ports_downstream + 1) * len(port_attributes) + len(vessel_attributes)\n",
    "\n",
    "    def __call__(self, decision_event, snapshot_list):\n",
    "        tick, port_idx, vessel_idx = decision_event.tick, decision_event.port_idx, decision_event.vessel_idx\n",
    "        ticks = [tick - rt for rt in range(self._look_back-1)]\n",
    "        future_port_idx_list = snapshot_list[\"vessels\"][tick: vessel_idx: 'future_stop_list'].astype('int')\n",
    "        port_features = snapshot_list[\"ports\"][ticks: [port_idx] + list(future_port_idx_list): self._port_attributes]\n",
    "        vessel_features = snapshot_list[\"vessels\"][tick: vessel_idx: self._vessel_attributes]\n",
    "        state = np.concatenate((port_features, vessel_features))\n",
    "        return str(port_idx), state\n",
    "    \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Action Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "Action shaper is used to convert an agent's model output to an environment executable action. For this specific scenario, the output is a discrete index that corresponds to a percentage indicating the fraction of containers to be loaded to or discharged from the arriving vessel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maro.rl import ActionShaper\n",
    "from maro.simulator.scenarios.cim.common import Action\n",
    "\n",
    "\n",
    "class CIMActionShaper(ActionShaper):\n",
    "    def __init__(self, action_space):\n",
    "        super().__init__()\n",
    "        self._action_space = action_space\n",
    "        self._zero_action_index = action_space.index(0)\n",
    "\n",
    "    def __call__(self, model_action, decision_event, snapshot_list):\n",
    "        assert 0 <= model_action < len(self._action_space)\n",
    "        \n",
    "        scope = decision_event.action_scope\n",
    "        tick = decision_event.tick\n",
    "        port_idx = decision_event.port_idx\n",
    "        vessel_idx = decision_event.vessel_idx\n",
    "        port_empty = snapshot_list[\"ports\"][tick: port_idx: [\"empty\", \"full\", \"on_shipper\", \"on_consignee\"]][0]\n",
    "        vessel_remaining_space = snapshot_list[\"vessels\"][tick: vessel_idx: [\"empty\", \"full\", \"remaining_space\"]][2]\n",
    "        early_discharge = snapshot_list[\"vessels\"][tick:vessel_idx: \"early_discharge\"][0]\n",
    "     \n",
    "        if model_action < self._zero_action_index:\n",
    "            # The number of loaded containers must be less thean the vessel's remaining space.\n",
    "            actual_action = max(round(self._action_space[model_action] * port_empty), -vessel_remaining_space)\n",
    "        elif model_action > self._zero_action_index:\n",
    "            # In the case of an early discharge event, we need to subtract the early discharge amount from the expected \n",
    "            # discharge quote.   \n",
    "            plan_action = self._action_space[model_action] * (scope.discharge + early_discharge) - early_discharge\n",
    "            actual_action = round(plan_action) if plan_action > 0 else round(self._action_space[model_action] * scope.discharge)\n",
    "        else:\n",
    "            actual_action = 0\n",
    "\n",
    "        return Action(vessel_idx, port_idx, actual_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Experience Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "Experience shaper is used to convert an episode trajectory to trainable experiences for RL agents. For this specific scenario, the reward is a linear combination of fulfillment and shortage in a limited time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from maro.rl import ExperienceShaper\n",
    "\n",
    "\n",
    "class TruncatedExperienceShaper(ExperienceShaper):\n",
    "    def __init__(self, *, time_window: int, time_decay_factor: float, fulfillment_factor: float,\n",
    "                 shortage_factor: float):\n",
    "        super().__init__(reward_func=None)\n",
    "        self._time_window = time_window\n",
    "        self._time_decay_factor = time_decay_factor\n",
    "        self._fulfillment_factor = fulfillment_factor\n",
    "        self._shortage_factor = shortage_factor\n",
    "\n",
    "    def __call__(self, trajectory, snapshot_list):\n",
    "        experiences_by_agent = {}\n",
    "        for i in range(len(trajectory) - 1):\n",
    "            transition = trajectory[i]\n",
    "            agent_id = transition[\"agent_id\"]\n",
    "            if agent_id not in experiences_by_agent:\n",
    "                experiences_by_agent[agent_id] = defaultdict(list)\n",
    "            \n",
    "            experiences = experiences_by_agent[agent_id]\n",
    "            experiences[\"state\"].append(transition[\"state\"])\n",
    "            experiences[\"action\"].append(transition[\"action\"])\n",
    "            experiences[\"reward\"].append(self._compute_reward(transition[\"event\"], snapshot_list))\n",
    "            experiences[\"next_state\"].append(trajectory[i+1][\"state\"])\n",
    "\n",
    "        return experiences_by_agent\n",
    "\n",
    "    def _compute_reward(self, decision_event, snapshot_list):\n",
    "        start_tick = decision_event.tick + 1\n",
    "        end_tick = decision_event.tick + self._time_window\n",
    "        ticks = list(range(start_tick, end_tick))\n",
    "\n",
    "        # Calculate truncate reward.\n",
    "        future_fulfillment = snapshot_list[\"ports\"][ticks::\"fulfillment\"]\n",
    "        future_shortage = snapshot_list[\"ports\"][ticks::\"shortage\"]\n",
    "        decay_list = [self._time_decay_factor ** i for i in range(end_tick - start_tick)\n",
    "                      for _ in range(future_fulfillment.shape[0]//(end_tick-start_tick))]\n",
    "\n",
    "        tot_fulfillment = np.dot(future_fulfillment, decay_list)\n",
    "        tot_shortage = np.dot(future_shortage, decay_list)\n",
    "\n",
    "        return np.float(self._fulfillment_factor * tot_fulfillment - self._shortage_factor * tot_shortage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Agent](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#agent)\n",
    "\n",
    "For this scenario, the agent is the abstraction of a port. We choose DQN as our underlying learning algorithm with a TD-error-based sampling mechanism.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maro.rl import AbsAgent, ColumnBasedStore\n",
    "\n",
    "\n",
    "class CIMAgent(AbsAgent):\n",
    "    def __init__(self, name, algorithm, experience_pool: ColumnBasedStore, min_experiences_to_train,\n",
    "                 num_batches, batch_size):\n",
    "        super().__init__(name, algorithm, experience_pool)\n",
    "        self._min_experiences_to_train = min_experiences_to_train\n",
    "        self._num_batches = num_batches\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "    def train(self):\n",
    "        if len(self._experience_pool) < self._min_experiences_to_train:\n",
    "            return\n",
    "\n",
    "        for _ in range(self._num_batches):\n",
    "            indexes, sample = self._experience_pool.sample_by_key(\"loss\", self._batch_size)\n",
    "            state = np.asarray(sample[\"state\"])\n",
    "            action = np.asarray(sample[\"action\"])\n",
    "            reward = np.asarray(sample[\"reward\"])\n",
    "            next_state = np.asarray(sample[\"next_state\"])\n",
    "            loss = self._algorithm.train(state, action, reward, next_state)\n",
    "            self._experience_pool.update(indexes, {\"loss\": loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Agent Manager](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#agent-manager)\n",
    "\n",
    "The complexities of the environment can be isolated from the learning algorithm by using an AgentManager to manage individual agents. We define a function to create the agents and an agent manager class that implements the ``train`` method where the newly obtained experiences are stored in the agents' experience pools before training, in accordance with the DQN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import yaml\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import smooth_l1_loss\n",
    "from torch.optim import RMSprop\n",
    "\n",
    "from maro.rl import SimpleAgentManager, LearningModel, FullyConnectedNet, DQN, DQNHyperParams, ColumnBasedStore\n",
    "\n",
    "\n",
    "input_dim = 171\n",
    "num_actions = 21\n",
    "\n",
    "\n",
    "\n",
    "def create_dqn_agents(agent_id_list):\n",
    "    agent_dict = {}\n",
    "    for agent_id in agent_id_list:\n",
    "        eval_model = LearningModel(\n",
    "            decision_layers=FullyConnectedNet(\n",
    "                name=f'{agent_id}.policy',\n",
    "                input_dim=input_dim,\n",
    "                output_dim=num_actions,\n",
    "                activation=nn.LeakyReLU, \n",
    "                hidden_dims=[256, 128, 64],\n",
    "                softmax_enabled=False,\n",
    "                batch_norm_enabled=True,\n",
    "                dropout_p=.0\n",
    "            )\n",
    "        )\n",
    "\n",
    "        algorithm = DQN(\n",
    "            eval_model=eval_model,\n",
    "            optimizer_cls=RMSprop,\n",
    "            optimizer_params={\"lr\": 0.05},\n",
    "            loss_func=nn.functional.smooth_l1_loss,\n",
    "            hyper_params=DQNHyperParams(\n",
    "                num_actions=num_actions,\n",
    "                reward_decay=.0,\n",
    "                target_update_frequency=5,\n",
    "                tau=0.1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        experience_pool = ColumnBasedStore()\n",
    "        agent_dict[agent_id] = CIMAgent(\n",
    "            name=agent_id,\n",
    "            algorithm=algorithm,\n",
    "            experience_pool=experience_pool,\n",
    "            min_experiences_to_train=1024,\n",
    "            num_batches=10,\n",
    "            batch_size=128\n",
    "        )\n",
    "\n",
    "    return agent_dict\n",
    "\n",
    "\n",
    "class DQNAgentManager(SimpleAgentManager):\n",
    "    def train(self, experiences_by_agent, performance=None):\n",
    "        self._assert_train_mode()\n",
    "\n",
    "        # store experiences for each agent\n",
    "        for agent_id, exp in experiences_by_agent.items():\n",
    "            exp.update({\"loss\": [1e8] * len(list(exp.values())[0])})\n",
    "            self.agent_dict[agent_id].store_experiences(exp)\n",
    "\n",
    "        for agent in self.agent_dict.values():\n",
    "            agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop with [Actor and Learner](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#learner-and-actor)\n",
    "\n",
    "This code cell demonstrates the typical workflow of a learning policy's interaction with a MARO environment. \n",
    "\n",
    "- Initialize an environment with specific scenario and topology parameters. \n",
    "\n",
    "- Define scenario-specific components, e.g. shapers. \n",
    "\n",
    "- Create agents and an agent manager. \n",
    "\n",
    "- Create an actor and a learner to start the training process in which the agent manager interacts with the environment for collecting experiences and updating policies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:19:40 | single_host_cim_learner | INFO | ep 0 - performance: {'order_requirements': 2240000, 'container_shortage': 1449174, 'operation_number': 2877166}, epsilons: {'0': 0.4, '1': 0.4, '2': 0.4, '3': 0.4}\n",
      "08:19:44 | single_host_cim_learner | INFO | ep 1 - performance: {'order_requirements': 2240000, 'container_shortage': 1433716, 'operation_number': 2572894}, epsilons: {'0': 0.3983838383838384, '1': 0.3983838383838384, '2': 0.3983838383838384, '3': 0.3983838383838384}\n",
      "08:19:48 | single_host_cim_learner | INFO | ep 2 - performance: {'order_requirements': 2240000, 'container_shortage': 1508563, 'operation_number': 2738400}, epsilons: {'0': 0.39676767676767677, '1': 0.39676767676767677, '2': 0.39676767676767677, '3': 0.39676767676767677}\n",
      "08:19:53 | single_host_cim_learner | INFO | ep 3 - performance: {'order_requirements': 2240000, 'container_shortage': 1489816, 'operation_number': 2809858}, epsilons: {'0': 0.3951515151515152, '1': 0.3951515151515152, '2': 0.3951515151515152, '3': 0.3951515151515152}\n",
      "08:19:57 | single_host_cim_learner | INFO | ep 4 - performance: {'order_requirements': 2240000, 'container_shortage': 1123285, 'operation_number': 3364524}, epsilons: {'0': 0.39353535353535357, '1': 0.39353535353535357, '2': 0.39353535353535357, '3': 0.39353535353535357}\n",
      "08:20:01 | single_host_cim_learner | INFO | ep 5 - performance: {'order_requirements': 2240000, 'container_shortage': 1349341, 'operation_number': 2694390}, epsilons: {'0': 0.39191919191919194, '1': 0.39191919191919194, '2': 0.39191919191919194, '3': 0.39191919191919194}\n",
      "08:20:06 | single_host_cim_learner | INFO | ep 6 - performance: {'order_requirements': 2240000, 'container_shortage': 1064843, 'operation_number': 3079866}, epsilons: {'0': 0.3903030303030303, '1': 0.3903030303030303, '2': 0.3903030303030303, '3': 0.3903030303030303}\n",
      "08:20:10 | single_host_cim_learner | INFO | ep 7 - performance: {'order_requirements': 2240000, 'container_shortage': 1030570, 'operation_number': 3785677}, epsilons: {'0': 0.3886868686868687, '1': 0.3886868686868687, '2': 0.3886868686868687, '3': 0.3886868686868687}\n",
      "08:20:15 | single_host_cim_learner | INFO | ep 8 - performance: {'order_requirements': 2240000, 'container_shortage': 1518994, 'operation_number': 2751331}, epsilons: {'0': 0.38707070707070707, '1': 0.38707070707070707, '2': 0.38707070707070707, '3': 0.38707070707070707}\n",
      "08:20:20 | single_host_cim_learner | INFO | ep 9 - performance: {'order_requirements': 2240000, 'container_shortage': 1263743, 'operation_number': 3811452}, epsilons: {'0': 0.3854545454545455, '1': 0.3854545454545455, '2': 0.3854545454545455, '3': 0.3854545454545455}\n",
      "08:20:24 | single_host_cim_learner | INFO | ep 10 - performance: {'order_requirements': 2240000, 'container_shortage': 1283297, 'operation_number': 2929005}, epsilons: {'0': 0.38383838383838387, '1': 0.38383838383838387, '2': 0.38383838383838387, '3': 0.38383838383838387}\n",
      "08:20:29 | single_host_cim_learner | INFO | ep 11 - performance: {'order_requirements': 2240000, 'container_shortage': 1218838, 'operation_number': 3655184}, epsilons: {'0': 0.38222222222222224, '1': 0.38222222222222224, '2': 0.38222222222222224, '3': 0.38222222222222224}\n",
      "08:20:34 | single_host_cim_learner | INFO | ep 12 - performance: {'order_requirements': 2240000, 'container_shortage': 1661433, 'operation_number': 2834056}, epsilons: {'0': 0.3806060606060606, '1': 0.3806060606060606, '2': 0.3806060606060606, '3': 0.3806060606060606}\n",
      "08:20:38 | single_host_cim_learner | INFO | ep 13 - performance: {'order_requirements': 2240000, 'container_shortage': 998497, 'operation_number': 4331405}, epsilons: {'0': 0.378989898989899, '1': 0.378989898989899, '2': 0.378989898989899, '3': 0.378989898989899}\n",
      "08:20:43 | single_host_cim_learner | INFO | ep 14 - performance: {'order_requirements': 2240000, 'container_shortage': 817916, 'operation_number': 4062977}, epsilons: {'0': 0.3773737373737374, '1': 0.3773737373737374, '2': 0.3773737373737374, '3': 0.3773737373737374}\n",
      "08:20:47 | single_host_cim_learner | INFO | ep 15 - performance: {'order_requirements': 2240000, 'container_shortage': 1205514, 'operation_number': 3433622}, epsilons: {'0': 0.3757575757575758, '1': 0.3757575757575758, '2': 0.3757575757575758, '3': 0.3757575757575758}\n",
      "08:20:52 | single_host_cim_learner | INFO | ep 16 - performance: {'order_requirements': 2240000, 'container_shortage': 1031884, 'operation_number': 3870460}, epsilons: {'0': 0.37414141414141416, '1': 0.37414141414141416, '2': 0.37414141414141416, '3': 0.37414141414141416}\n",
      "08:20:56 | single_host_cim_learner | INFO | ep 17 - performance: {'order_requirements': 2240000, 'container_shortage': 810135, 'operation_number': 4242833}, epsilons: {'0': 0.37252525252525254, '1': 0.37252525252525254, '2': 0.37252525252525254, '3': 0.37252525252525254}\n",
      "08:21:01 | single_host_cim_learner | INFO | ep 18 - performance: {'order_requirements': 2240000, 'container_shortage': 1169174, 'operation_number': 3537445}, epsilons: {'0': 0.3709090909090909, '1': 0.3709090909090909, '2': 0.3709090909090909, '3': 0.3709090909090909}\n",
      "08:21:06 | single_host_cim_learner | INFO | ep 19 - performance: {'order_requirements': 2240000, 'container_shortage': 955743, 'operation_number': 4069342}, epsilons: {'0': 0.36929292929292934, '1': 0.36929292929292934, '2': 0.36929292929292934, '3': 0.36929292929292934}\n",
      "08:21:10 | single_host_cim_learner | INFO | ep 20 - performance: {'order_requirements': 2240000, 'container_shortage': 834081, 'operation_number': 4349373}, epsilons: {'0': 0.3676767676767677, '1': 0.3676767676767677, '2': 0.3676767676767677, '3': 0.3676767676767677}\n",
      "08:21:15 | single_host_cim_learner | INFO | ep 21 - performance: {'order_requirements': 2240000, 'container_shortage': 887920, 'operation_number': 4085329}, epsilons: {'0': 0.3660606060606061, '1': 0.3660606060606061, '2': 0.3660606060606061, '3': 0.3660606060606061}\n",
      "08:21:19 | single_host_cim_learner | INFO | ep 22 - performance: {'order_requirements': 2240000, 'container_shortage': 968113, 'operation_number': 4141775}, epsilons: {'0': 0.36444444444444446, '1': 0.36444444444444446, '2': 0.36444444444444446, '3': 0.36444444444444446}\n",
      "08:21:24 | single_host_cim_learner | INFO | ep 23 - performance: {'order_requirements': 2240000, 'container_shortage': 1007433, 'operation_number': 3887778}, epsilons: {'0': 0.36282828282828283, '1': 0.36282828282828283, '2': 0.36282828282828283, '3': 0.36282828282828283}\n",
      "08:21:29 | single_host_cim_learner | INFO | ep 24 - performance: {'order_requirements': 2240000, 'container_shortage': 872307, 'operation_number': 4125882}, epsilons: {'0': 0.3612121212121212, '1': 0.3612121212121212, '2': 0.3612121212121212, '3': 0.3612121212121212}\n",
      "08:21:34 | single_host_cim_learner | INFO | ep 25 - performance: {'order_requirements': 2240000, 'container_shortage': 982211, 'operation_number': 4188103}, epsilons: {'0': 0.3595959595959596, '1': 0.3595959595959596, '2': 0.3595959595959596, '3': 0.3595959595959596}\n",
      "08:21:38 | single_host_cim_learner | INFO | ep 26 - performance: {'order_requirements': 2240000, 'container_shortage': 1044675, 'operation_number': 4238421}, epsilons: {'0': 0.357979797979798, '1': 0.357979797979798, '2': 0.357979797979798, '3': 0.357979797979798}\n",
      "08:21:43 | single_host_cim_learner | INFO | ep 27 - performance: {'order_requirements': 2240000, 'container_shortage': 1087284, 'operation_number': 3871621}, epsilons: {'0': 0.3563636363636364, '1': 0.3563636363636364, '2': 0.3563636363636364, '3': 0.3563636363636364}\n",
      "08:21:48 | single_host_cim_learner | INFO | ep 28 - performance: {'order_requirements': 2240000, 'container_shortage': 766053, 'operation_number': 3905529}, epsilons: {'0': 0.35474747474747476, '1': 0.35474747474747476, '2': 0.35474747474747476, '3': 0.35474747474747476}\n",
      "08:21:52 | single_host_cim_learner | INFO | ep 29 - performance: {'order_requirements': 2240000, 'container_shortage': 866625, 'operation_number': 4174561}, epsilons: {'0': 0.35313131313131313, '1': 0.35313131313131313, '2': 0.35313131313131313, '3': 0.35313131313131313}\n",
      "08:21:57 | single_host_cim_learner | INFO | ep 30 - performance: {'order_requirements': 2240000, 'container_shortage': 970164, 'operation_number': 3620473}, epsilons: {'0': 0.3515151515151515, '1': 0.3515151515151515, '2': 0.3515151515151515, '3': 0.3515151515151515}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:22:02 | single_host_cim_learner | INFO | ep 31 - performance: {'order_requirements': 2240000, 'container_shortage': 589462, 'operation_number': 4166597}, epsilons: {'0': 0.34989898989898993, '1': 0.34989898989898993, '2': 0.34989898989898993, '3': 0.34989898989898993}\n",
      "08:22:06 | single_host_cim_learner | INFO | ep 32 - performance: {'order_requirements': 2240000, 'container_shortage': 651137, 'operation_number': 3812302}, epsilons: {'0': 0.3482828282828283, '1': 0.3482828282828283, '2': 0.3482828282828283, '3': 0.3482828282828283}\n",
      "08:22:11 | single_host_cim_learner | INFO | ep 33 - performance: {'order_requirements': 2240000, 'container_shortage': 506324, 'operation_number': 4250385}, epsilons: {'0': 0.3466666666666667, '1': 0.3466666666666667, '2': 0.3466666666666667, '3': 0.3466666666666667}\n",
      "08:22:16 | single_host_cim_learner | INFO | ep 34 - performance: {'order_requirements': 2240000, 'container_shortage': 656772, 'operation_number': 4013839}, epsilons: {'0': 0.34505050505050505, '1': 0.34505050505050505, '2': 0.34505050505050505, '3': 0.34505050505050505}\n",
      "08:22:20 | single_host_cim_learner | INFO | ep 35 - performance: {'order_requirements': 2240000, 'container_shortage': 549707, 'operation_number': 4060300}, epsilons: {'0': 0.3434343434343434, '1': 0.3434343434343434, '2': 0.3434343434343434, '3': 0.3434343434343434}\n",
      "08:22:25 | single_host_cim_learner | INFO | ep 36 - performance: {'order_requirements': 2240000, 'container_shortage': 608510, 'operation_number': 4065739}, epsilons: {'0': 0.3418181818181818, '1': 0.3418181818181818, '2': 0.3418181818181818, '3': 0.3418181818181818}\n",
      "08:22:30 | single_host_cim_learner | INFO | ep 37 - performance: {'order_requirements': 2240000, 'container_shortage': 533948, 'operation_number': 4050012}, epsilons: {'0': 0.3402020202020202, '1': 0.3402020202020202, '2': 0.3402020202020202, '3': 0.3402020202020202}\n",
      "08:22:34 | single_host_cim_learner | INFO | ep 38 - performance: {'order_requirements': 2240000, 'container_shortage': 506934, 'operation_number': 4276627}, epsilons: {'0': 0.3385858585858586, '1': 0.3385858585858586, '2': 0.3385858585858586, '3': 0.3385858585858586}\n",
      "08:22:39 | single_host_cim_learner | INFO | ep 39 - performance: {'order_requirements': 2240000, 'container_shortage': 516833, 'operation_number': 4413279}, epsilons: {'0': 0.336969696969697, '1': 0.336969696969697, '2': 0.336969696969697, '3': 0.336969696969697}\n",
      "08:22:44 | single_host_cim_learner | INFO | ep 40 - performance: {'order_requirements': 2240000, 'container_shortage': 497496, 'operation_number': 4473180}, epsilons: {'0': 0.33535353535353535, '1': 0.33535353535353535, '2': 0.33535353535353535, '3': 0.33535353535353535}\n",
      "08:22:48 | single_host_cim_learner | INFO | ep 41 - performance: {'order_requirements': 2240000, 'container_shortage': 866223, 'operation_number': 4156194}, epsilons: {'0': 0.3337373737373738, '1': 0.3337373737373738, '2': 0.3337373737373738, '3': 0.3337373737373738}\n",
      "08:22:53 | single_host_cim_learner | INFO | ep 42 - performance: {'order_requirements': 2240000, 'container_shortage': 446579, 'operation_number': 4225675}, epsilons: {'0': 0.33212121212121215, '1': 0.33212121212121215, '2': 0.33212121212121215, '3': 0.33212121212121215}\n",
      "08:22:58 | single_host_cim_learner | INFO | ep 43 - performance: {'order_requirements': 2240000, 'container_shortage': 400190, 'operation_number': 4255237}, epsilons: {'0': 0.3305050505050505, '1': 0.3305050505050505, '2': 0.3305050505050505, '3': 0.3305050505050505}\n",
      "08:23:02 | single_host_cim_learner | INFO | ep 44 - performance: {'order_requirements': 2240000, 'container_shortage': 466887, 'operation_number': 4216786}, epsilons: {'0': 0.3288888888888889, '1': 0.3288888888888889, '2': 0.3288888888888889, '3': 0.3288888888888889}\n",
      "08:23:07 | single_host_cim_learner | INFO | ep 45 - performance: {'order_requirements': 2240000, 'container_shortage': 499424, 'operation_number': 4268237}, epsilons: {'0': 0.32727272727272727, '1': 0.32727272727272727, '2': 0.32727272727272727, '3': 0.32727272727272727}\n",
      "08:23:12 | single_host_cim_learner | INFO | ep 46 - performance: {'order_requirements': 2240000, 'container_shortage': 525049, 'operation_number': 4131713}, epsilons: {'0': 0.32565656565656564, '1': 0.32565656565656564, '2': 0.32565656565656564, '3': 0.32565656565656564}\n",
      "08:23:17 | single_host_cim_learner | INFO | ep 47 - performance: {'order_requirements': 2240000, 'container_shortage': 510123, 'operation_number': 4232019}, epsilons: {'0': 0.324040404040404, '1': 0.324040404040404, '2': 0.324040404040404, '3': 0.324040404040404}\n",
      "08:23:21 | single_host_cim_learner | INFO | ep 48 - performance: {'order_requirements': 2240000, 'container_shortage': 452370, 'operation_number': 4175531}, epsilons: {'0': 0.32242424242424245, '1': 0.32242424242424245, '2': 0.32242424242424245, '3': 0.32242424242424245}\n",
      "08:23:26 | single_host_cim_learner | INFO | ep 49 - performance: {'order_requirements': 2240000, 'container_shortage': 424113, 'operation_number': 4204467}, epsilons: {'0': 0.3208080808080808, '1': 0.3208080808080808, '2': 0.3208080808080808, '3': 0.3208080808080808}\n",
      "08:23:31 | single_host_cim_learner | INFO | ep 50 - performance: {'order_requirements': 2240000, 'container_shortage': 486622, 'operation_number': 4177974}, epsilons: {'0': 0.31676767676767675, '1': 0.31676767676767675, '2': 0.31676767676767675, '3': 0.31676767676767675}\n",
      "08:23:36 | single_host_cim_learner | INFO | ep 51 - performance: {'order_requirements': 2240000, 'container_shortage': 477881, 'operation_number': 4023553}, epsilons: {'0': 0.3103030303030303, '1': 0.3103030303030303, '2': 0.3103030303030303, '3': 0.3103030303030303}\n",
      "08:23:41 | single_host_cim_learner | INFO | ep 52 - performance: {'order_requirements': 2240000, 'container_shortage': 546463, 'operation_number': 4020774}, epsilons: {'0': 0.3038383838383838, '1': 0.3038383838383838, '2': 0.3038383838383838, '3': 0.3038383838383838}\n",
      "08:23:45 | single_host_cim_learner | INFO | ep 53 - performance: {'order_requirements': 2240000, 'container_shortage': 461636, 'operation_number': 4188035}, epsilons: {'0': 0.2973737373737374, '1': 0.2973737373737374, '2': 0.2973737373737374, '3': 0.2973737373737374}\n",
      "08:23:50 | single_host_cim_learner | INFO | ep 54 - performance: {'order_requirements': 2240000, 'container_shortage': 570378, 'operation_number': 3776713}, epsilons: {'0': 0.29090909090909095, '1': 0.29090909090909095, '2': 0.29090909090909095, '3': 0.29090909090909095}\n",
      "08:23:55 | single_host_cim_learner | INFO | ep 55 - performance: {'order_requirements': 2240000, 'container_shortage': 538013, 'operation_number': 4023664}, epsilons: {'0': 0.28444444444444444, '1': 0.28444444444444444, '2': 0.28444444444444444, '3': 0.28444444444444444}\n",
      "08:24:00 | single_host_cim_learner | INFO | ep 56 - performance: {'order_requirements': 2240000, 'container_shortage': 580577, 'operation_number': 3894939}, epsilons: {'0': 0.277979797979798, '1': 0.277979797979798, '2': 0.277979797979798, '3': 0.277979797979798}\n",
      "08:24:05 | single_host_cim_learner | INFO | ep 57 - performance: {'order_requirements': 2240000, 'container_shortage': 470579, 'operation_number': 4114149}, epsilons: {'0': 0.2715151515151515, '1': 0.2715151515151515, '2': 0.2715151515151515, '3': 0.2715151515151515}\n",
      "08:24:10 | single_host_cim_learner | INFO | ep 58 - performance: {'order_requirements': 2240000, 'container_shortage': 599047, 'operation_number': 3703140}, epsilons: {'0': 0.26505050505050504, '1': 0.26505050505050504, '2': 0.26505050505050504, '3': 0.26505050505050504}\n",
      "08:24:15 | single_host_cim_learner | INFO | ep 59 - performance: {'order_requirements': 2240000, 'container_shortage': 592780, 'operation_number': 3752613}, epsilons: {'0': 0.25858585858585864, '1': 0.25858585858585864, '2': 0.25858585858585864, '3': 0.25858585858585864}\n",
      "08:24:20 | single_host_cim_learner | INFO | ep 60 - performance: {'order_requirements': 2240000, 'container_shortage': 626194, 'operation_number': 3682348}, epsilons: {'0': 0.25212121212121213, '1': 0.25212121212121213, '2': 0.25212121212121213, '3': 0.25212121212121213}\n",
      "08:24:25 | single_host_cim_learner | INFO | ep 61 - performance: {'order_requirements': 2240000, 'container_shortage': 331137, 'operation_number': 4097250}, epsilons: {'0': 0.24565656565656568, '1': 0.24565656565656568, '2': 0.24565656565656568, '3': 0.24565656565656568}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:24:30 | single_host_cim_learner | INFO | ep 62 - performance: {'order_requirements': 2240000, 'container_shortage': 427942, 'operation_number': 3986817}, epsilons: {'0': 0.23919191919191918, '1': 0.23919191919191918, '2': 0.23919191919191918, '3': 0.23919191919191918}\n",
      "08:24:34 | single_host_cim_learner | INFO | ep 63 - performance: {'order_requirements': 2240000, 'container_shortage': 349003, 'operation_number': 4169958}, epsilons: {'0': 0.23272727272727273, '1': 0.23272727272727273, '2': 0.23272727272727273, '3': 0.23272727272727273}\n",
      "08:24:39 | single_host_cim_learner | INFO | ep 64 - performance: {'order_requirements': 2240000, 'container_shortage': 443412, 'operation_number': 4040920}, epsilons: {'0': 0.22626262626262622, '1': 0.22626262626262622, '2': 0.22626262626262622, '3': 0.22626262626262622}\n",
      "08:24:44 | single_host_cim_learner | INFO | ep 65 - performance: {'order_requirements': 2240000, 'container_shortage': 491950, 'operation_number': 3867277}, epsilons: {'0': 0.2197979797979798, '1': 0.2197979797979798, '2': 0.2197979797979798, '3': 0.2197979797979798}\n",
      "08:24:49 | single_host_cim_learner | INFO | ep 66 - performance: {'order_requirements': 2240000, 'container_shortage': 555217, 'operation_number': 4051336}, epsilons: {'0': 0.21333333333333337, '1': 0.21333333333333337, '2': 0.21333333333333337, '3': 0.21333333333333337}\n",
      "08:24:54 | single_host_cim_learner | INFO | ep 67 - performance: {'order_requirements': 2240000, 'container_shortage': 453428, 'operation_number': 3853567}, epsilons: {'0': 0.20686868686868687, '1': 0.20686868686868687, '2': 0.20686868686868687, '3': 0.20686868686868687}\n",
      "08:24:59 | single_host_cim_learner | INFO | ep 68 - performance: {'order_requirements': 2240000, 'container_shortage': 502834, 'operation_number': 3935391}, epsilons: {'0': 0.20040404040404042, '1': 0.20040404040404042, '2': 0.20040404040404042, '3': 0.20040404040404042}\n",
      "08:25:04 | single_host_cim_learner | INFO | ep 69 - performance: {'order_requirements': 2240000, 'container_shortage': 651275, 'operation_number': 4529383}, epsilons: {'0': 0.1939393939393939, '1': 0.1939393939393939, '2': 0.1939393939393939, '3': 0.1939393939393939}\n",
      "08:25:09 | single_host_cim_learner | INFO | ep 70 - performance: {'order_requirements': 2240000, 'container_shortage': 450364, 'operation_number': 3752971}, epsilons: {'0': 0.1874747474747475, '1': 0.1874747474747475, '2': 0.1874747474747475, '3': 0.1874747474747475}\n",
      "08:25:14 | single_host_cim_learner | INFO | ep 71 - performance: {'order_requirements': 2240000, 'container_shortage': 380907, 'operation_number': 3936188}, epsilons: {'0': 0.18101010101010104, '1': 0.18101010101010104, '2': 0.18101010101010104, '3': 0.18101010101010104}\n",
      "08:25:18 | single_host_cim_learner | INFO | ep 72 - performance: {'order_requirements': 2240000, 'container_shortage': 342391, 'operation_number': 4033114}, epsilons: {'0': 0.17454545454545453, '1': 0.17454545454545453, '2': 0.17454545454545453, '3': 0.17454545454545453}\n",
      "08:25:23 | single_host_cim_learner | INFO | ep 73 - performance: {'order_requirements': 2240000, 'container_shortage': 391236, 'operation_number': 3948352}, epsilons: {'0': 0.1680808080808081, '1': 0.1680808080808081, '2': 0.1680808080808081, '3': 0.1680808080808081}\n",
      "08:25:28 | single_host_cim_learner | INFO | ep 74 - performance: {'order_requirements': 2240000, 'container_shortage': 698458, 'operation_number': 3325779}, epsilons: {'0': 0.1616161616161616, '1': 0.1616161616161616, '2': 0.1616161616161616, '3': 0.1616161616161616}\n",
      "08:25:33 | single_host_cim_learner | INFO | ep 75 - performance: {'order_requirements': 2240000, 'container_shortage': 370796, 'operation_number': 4465673}, epsilons: {'0': 0.15515151515151515, '1': 0.15515151515151515, '2': 0.15515151515151515, '3': 0.15515151515151515}\n",
      "08:25:38 | single_host_cim_learner | INFO | ep 76 - performance: {'order_requirements': 2240000, 'container_shortage': 140750, 'operation_number': 4611626}, epsilons: {'0': 0.14868686868686873, '1': 0.14868686868686873, '2': 0.14868686868686873, '3': 0.14868686868686873}\n",
      "08:25:43 | single_host_cim_learner | INFO | ep 77 - performance: {'order_requirements': 2240000, 'container_shortage': 159430, 'operation_number': 4627419}, epsilons: {'0': 0.14222222222222222, '1': 0.14222222222222222, '2': 0.14222222222222222, '3': 0.14222222222222222}\n",
      "08:25:48 | single_host_cim_learner | INFO | ep 78 - performance: {'order_requirements': 2240000, 'container_shortage': 79279, 'operation_number': 4574175}, epsilons: {'0': 0.13575757575757577, '1': 0.13575757575757577, '2': 0.13575757575757577, '3': 0.13575757575757577}\n",
      "08:25:53 | single_host_cim_learner | INFO | ep 79 - performance: {'order_requirements': 2240000, 'container_shortage': 157224, 'operation_number': 4481568}, epsilons: {'0': 0.12929292929292927, '1': 0.12929292929292927, '2': 0.12929292929292927, '3': 0.12929292929292927}\n",
      "08:25:58 | single_host_cim_learner | INFO | ep 80 - performance: {'order_requirements': 2240000, 'container_shortage': 107323, 'operation_number': 4483160}, epsilons: {'0': 0.12282828282828284, '1': 0.12282828282828284, '2': 0.12282828282828284, '3': 0.12282828282828284}\n",
      "08:26:03 | single_host_cim_learner | INFO | ep 81 - performance: {'order_requirements': 2240000, 'container_shortage': 115601, 'operation_number': 4583155}, epsilons: {'0': 0.11636363636363634, '1': 0.11636363636363634, '2': 0.11636363636363634, '3': 0.11636363636363634}\n",
      "08:26:08 | single_host_cim_learner | INFO | ep 82 - performance: {'order_requirements': 2240000, 'container_shortage': 132296, 'operation_number': 4547233}, epsilons: {'0': 0.1098989898989899, '1': 0.1098989898989899, '2': 0.1098989898989899, '3': 0.1098989898989899}\n",
      "08:26:13 | single_host_cim_learner | INFO | ep 83 - performance: {'order_requirements': 2240000, 'container_shortage': 80712, 'operation_number': 4558938}, epsilons: {'0': 0.10343434343434346, '1': 0.10343434343434346, '2': 0.10343434343434346, '3': 0.10343434343434346}\n",
      "08:26:18 | single_host_cim_learner | INFO | ep 84 - performance: {'order_requirements': 2240000, 'container_shortage': 155909, 'operation_number': 4617332}, epsilons: {'0': 0.09696969696969696, '1': 0.09696969696969696, '2': 0.09696969696969696, '3': 0.09696969696969696}\n",
      "08:26:23 | single_host_cim_learner | INFO | ep 85 - performance: {'order_requirements': 2240000, 'container_shortage': 99228, 'operation_number': 4594562}, epsilons: {'0': 0.09050505050505052, '1': 0.09050505050505052, '2': 0.09050505050505052, '3': 0.09050505050505052}\n",
      "08:26:28 | single_host_cim_learner | INFO | ep 86 - performance: {'order_requirements': 2240000, 'container_shortage': 85741, 'operation_number': 4516614}, epsilons: {'0': 0.08404040404040401, '1': 0.08404040404040401, '2': 0.08404040404040401, '3': 0.08404040404040401}\n",
      "08:26:33 | single_host_cim_learner | INFO | ep 87 - performance: {'order_requirements': 2240000, 'container_shortage': 27260, 'operation_number': 4476453}, epsilons: {'0': 0.07757575757575758, '1': 0.07757575757575758, '2': 0.07757575757575758, '3': 0.07757575757575758}\n",
      "08:26:38 | single_host_cim_learner | INFO | ep 88 - performance: {'order_requirements': 2240000, 'container_shortage': 81625, 'operation_number': 4424191}, epsilons: {'0': 0.07111111111111114, '1': 0.07111111111111114, '2': 0.07111111111111114, '3': 0.07111111111111114}\n",
      "08:26:43 | single_host_cim_learner | INFO | ep 89 - performance: {'order_requirements': 2240000, 'container_shortage': 39858, 'operation_number': 4517449}, epsilons: {'0': 0.06464646464646463, '1': 0.06464646464646463, '2': 0.06464646464646463, '3': 0.06464646464646463}\n",
      "08:26:48 | single_host_cim_learner | INFO | ep 90 - performance: {'order_requirements': 2240000, 'container_shortage': 68142, 'operation_number': 4411657}, epsilons: {'0': 0.0581818181818182, '1': 0.0581818181818182, '2': 0.0581818181818182, '3': 0.0581818181818182}\n",
      "08:26:53 | single_host_cim_learner | INFO | ep 91 - performance: {'order_requirements': 2240000, 'container_shortage': 35214, 'operation_number': 4514769}, epsilons: {'0': 0.051717171717171696, '1': 0.051717171717171696, '2': 0.051717171717171696, '3': 0.051717171717171696}\n",
      "08:26:58 | single_host_cim_learner | INFO | ep 92 - performance: {'order_requirements': 2240000, 'container_shortage': 73510, 'operation_number': 4448161}, epsilons: {'0': 0.04525252525252526, '1': 0.04525252525252526, '2': 0.04525252525252526, '3': 0.04525252525252526}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:27:03 | single_host_cim_learner | INFO | ep 93 - performance: {'order_requirements': 2240000, 'container_shortage': 54462, 'operation_number': 4504207}, epsilons: {'0': 0.03878787878787875, '1': 0.03878787878787875, '2': 0.03878787878787875, '3': 0.03878787878787875}\n",
      "08:27:08 | single_host_cim_learner | INFO | ep 94 - performance: {'order_requirements': 2240000, 'container_shortage': 17770, 'operation_number': 4507162}, epsilons: {'0': 0.032323232323232316, '1': 0.032323232323232316, '2': 0.032323232323232316, '3': 0.032323232323232316}\n",
      "08:27:13 | single_host_cim_learner | INFO | ep 95 - performance: {'order_requirements': 2240000, 'container_shortage': 31159, 'operation_number': 4457436}, epsilons: {'0': 0.025858585858585883, '1': 0.025858585858585883, '2': 0.025858585858585883, '3': 0.025858585858585883}\n",
      "08:27:18 | single_host_cim_learner | INFO | ep 96 - performance: {'order_requirements': 2240000, 'container_shortage': 29988, 'operation_number': 4428244}, epsilons: {'0': 0.019393939393939377, '1': 0.019393939393939377, '2': 0.019393939393939377, '3': 0.019393939393939377}\n",
      "08:27:23 | single_host_cim_learner | INFO | ep 97 - performance: {'order_requirements': 2240000, 'container_shortage': 5791, 'operation_number': 4473662}, epsilons: {'0': 0.012929292929292941, '1': 0.012929292929292941, '2': 0.012929292929292941, '3': 0.012929292929292941}\n",
      "08:27:28 | single_host_cim_learner | INFO | ep 98 - performance: {'order_requirements': 2240000, 'container_shortage': 8556, 'operation_number': 4451186}, epsilons: {'0': 0.006464646464646435, '1': 0.006464646464646435, '2': 0.006464646464646435, '3': 0.006464646464646435}\n",
      "08:27:33 | single_host_cim_learner | INFO | ep 99 - performance: {'order_requirements': 2240000, 'container_shortage': 0, 'operation_number': 4457874}, epsilons: {'0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from maro.simulator import Env\n",
    "from maro.rl import SimpleLearner, SimpleActor, AgentManagerMode, TwoPhaseLinearExplorer\n",
    "from maro.utils import Logger, LogFormat\n",
    "\n",
    "# Step 1: initialize a CIM environment for using a toy dataset. \n",
    "env = Env(\"cim\", \"toy.4p_ssdd_l0.0\", durations=1120)\n",
    "agent_id_list = [str(agent_id) for agent_id in env.agent_idx_list]\n",
    "\n",
    "# Step 2: create state, action and experience shapers. We also need to create an explorer here due to the \n",
    "# greedy nature of the DQN algorithm.  \n",
    "state_shaper = CIMStateShaper(look_back=7, max_ports_downstream=2, \n",
    "                              port_attributes=[\"empty\", \"full\", \"on_shipper\", \"on_consignee\", \n",
    "                                               \"booking\", \"shortage\", \"fulfillment\"],\n",
    "                              vessel_attributes=[\"empty\", \"full\", \"remaining_space\"]\n",
    "                             )\n",
    "\n",
    "action_shaper = CIMActionShaper(action_space=list(np.linspace(-1.0, 1.0, num_actions)))\n",
    "\n",
    "experience_shaper = TruncatedExperienceShaper(time_window=100, fulfillment_factor=1.0, shortage_factor=1.0,\n",
    "                                              time_decay_factor=0.97)\n",
    "\n",
    "# Step 3: create an agent manager.\n",
    "agent_manager = DQNAgentManager(name=\"cim_learner\",\n",
    "                                mode=AgentManagerMode.TRAIN_INFERENCE,\n",
    "                                agent_dict=create_dqn_agents(agent_id_list),\n",
    "                                state_shaper=state_shaper,\n",
    "                                action_shaper=action_shaper,\n",
    "                                experience_shaper=experience_shaper)\n",
    "\n",
    "# Step 4: Create an actor and a learner to start the training process. \n",
    "actor = SimpleActor(env, agent_manager)\n",
    "learner = SimpleLearner(trainable_agents=agent_manager, actor=actor, \n",
    "                        explorer=TwoPhaseLinearExplorer(start_eps=0.4, mid_eps=0.32, end_eps=0.0, split_point=0.5),\n",
    "                        logger=Logger(\"single_host_cim_learner\", format_=LogFormat.simple, auto_timestamp=False))\n",
    "\n",
    "learner.train(max_episode=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
