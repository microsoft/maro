experiment_name: cgf
env:
  scenario: "ecr"
  topology: "4p_ssdd_l0.8"
  max_tick: 224
train:
  max_ep: 200 # max episode
  batch_num: 10
  batch_size: 256
  min_train_experience_num: 256 # when experience number is less than it, will not trigger train
  reward_shaping: 'cgf'
  ddpg:
    target_update_frequency:  5 # target network update frequency
    dropout: 0.0 # dropout parameter
    gamma: 0.0 # reward decay
    tau: 0.1 # soft update
    critic_lr: 0.001 # learning rate
    actor_lr: 0.00005
  exploration:
    theta: 1
    sigma: 1000
  seed: 1024
test:
  max_ep: 10 # max episode
  seed: 2048
qnet:
  seed: 0
log:
  runner:
    enable: true
  agent:
    enable: true
  ddpg:
    enable: true
    dropout: 0.95
  actor:
    enable: false
  critic:
    enable: false