experiment_name: "test_ep500"
env:
  scenario: "ecr"
  topology: "5p_ssddd_l0.0"
  max_tick: 200
train:
  max_ep: 500 # max episode
  batch_num: 10
  batch_size: 128
  min_train_experience_num: 1024 # when experience number is less than it, will not trigger train
  reward_shaping: 'gf'
  dqn:
    target_update_frequency: 5 # target network update frequency
    dropout_p: 0.0 # dropout parameter
    gamma: 0.0 # reward decay
    tau: 0.1 # soft update
    lr: 0.05 # learning rate
  exploration:
    max_eps: 0.4 # max epsilon
    phase_split_point: 0.5 # exploration two phase split point
    first_phase_reduce_proportion: 0.8 # first phase reduce proportion of max_eps 
  seed: 1024
test:
  max_ep: 1 # max episode
  seed: 2048
qnet:
  seed: 0
log:
  runner:
    enable: true
  agent:
    enable: true
  dqn:
    enable: true
    dropout_p: 0.95
  qnet:
    enable: true
  dashboard:
    enable: true
dashboard:
  enable: false
  influxdb:
    host: localhost
    port: 50301
    use_udp: true
    udp_port: 50304
  ranklist:
    enable: false
    author: your_name
    commit: your_commit

docker_image: 'maro_dist'

redis:
  host: localhost
  port: 6379

distributed:
  mode: async
  environment_runner:
    num: 2
    peers:
      - 'learner'
  learner:
    num: 5
    peers:
      - 'environment_runner'

  resources:
    environment_runner:
      CPU: 500m
      GPU: 1
      memory: 128Mi # MB
    learner:
      CPU: 500m
      GPU: 2
      memory: 256Mi # MB

