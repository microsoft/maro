env:
  scenario: "cim"
  topology: "toy.4p_ssdd_l0.0"
  durations: 1120
general:
  total_training_episodes: 500 # max episode
state_shaping:
  look_back: 7
  max_ports_downstream: 2
  port_attributes:
    - "empty"
    - "full"
    - "on_shipper"
    - "on_consignee"
    - "booking"
    - "shortage"
    - "fulfillment"
  vessel_attributes:
    - "empty"
    - "full"
    - "remaining_space"
experience_shaping:
  time_window: 100
  fulfillment_factor: 1.0
  shortage_factor: 1.0
  time_decay_factor: 0.97
agents:
  algorithm:
    num_actions: 21
    policy_model:
      hidden_dims:
        - 256
        - 128
        - 64
      softmax_enabled: true
      batch_norm_enabled: false
    value_model:
      hidden_dims:
        - 256
        - 128
        - 64
      softmax_enabled: false
      batch_norm_enabled: true
    policy_optimizer:
      lr: 0.001
    value_optimizer:
      lr: 0.001
    hyper_parameters:
      reward_decay: .0
      policy_train_iters: 1
      value_train_iters: 10
      k: 1
      lam: 0.0
  seed: 1024   # for reproducibility
distributed:
  group_name: "ac_distributed_test"
  actor:
    peer: {"actor": 1}
  learner:
    peer: {"actor_worker": 1}
  redis:
    host_name: "localhost"
    port: 6379
