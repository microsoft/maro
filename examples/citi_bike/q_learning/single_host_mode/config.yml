experiment_name: "TRAIN_MAXTIC300000_LR0.005_1e-4_BS_256_DR20_S_0.2"
env:
  scenario: "bike"
  topology: "train"
  start_tick: 0 
  max_tick: 300000 # stop until the data steam end
  decision_mode: 0 # joint-->1,sequential-->0
train:
  max_ep: 300 # max episode
  batch_num: 2
  batch_size: 512
  min_train_experience_num: 256 # when experience number is less than it, will not trigger train
  reward_shaping: 'tc'
  dqn:
    share_parameter: false
    target_update_frequency: 5 # target network update frequency
    dropout_p: 0.0 # dropout parameter
    gamma: 0.0 # reward decay
    tau: 0.1 # soft update
    lr: 0.005 # learning rate
  exploration:
    max_eps: 0.5 # max epsilon
    phase_split_point: 0.5 # exploration two phase split point
    first_phase_reduce_proportion: 0.8 # first phase reduce proportion of max_eps
  reward:
    reward_factor: 0.0001
    shortage_factor: 1
    cost_factor: 0.5
  seed: 1024
test:
  max_ep: 5 # max episode
  seed: 2048
  topology: "train"
  start_tick: 480960 # 2019-12-01
  max_tick: 485960 # 480960 + 2000
qnet:
  seed: 0
log:
  runner:
    enable: true
  agent:
    enable: true
  dqn:
    enable: false
    dropout_p: 0.95
  qnet:
    enable: false
  dashboard:
    enable: false
dashboard:
  enable: true
  influxdb:
    host: localhost
    port: 50301
    use_udp: true
    udp_port: 50304
  ranklist:
    enable: false
    author: your_name
    commit: your_commit