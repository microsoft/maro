experiment_name: "BASE_MAXTIC2000_YEAR19_TRIP0_LR0.005_COST1"
env:
  scenario: "bike"
  topology: "train"
  start_tick: 0 
  max_tick: 2000 # stop until the data steam end # 525600 tick per year
train:
  max_ep: 300 # max episode
  batch_num: 10
  batch_size: 128
  min_train_experience_num: 128 # when experience number is less than it, will not trigger train
  reward_shaping: 'tc'
  dqn:
    target_update_frequency: 5 # target network update frequency
    dropout_p: 0.0 # dropout parameter
    gamma: 0.0 # reward decay
    tau: 0.1 # soft update
    lr: 0.005 # learning rate
  exploration:
    max_eps: 0.4 # max epsilon
    phase_split_point: 0.5 # exploration two phase split point
    first_phase_reduce_proportion: 0.8 # first phase reduce proportion of max_eps
  reward:
    shortage_factor: 1
    cost_factor: 1
  seed: 1024
test:
  max_ep: 5 # max episode
  seed: 2048
  topology: "train"
  start_tick: 480960 # 2019-12-01
  max_tick: 482960 # 480960 + 2000
qnet:
  seed: 0
log:
  runner:
    enable: true
  agent:
    enable: false
  dqn:
    enable: false
    dropout_p: 0.95
  qnet:
    enable: false
  dashboard:
    enable: false
dashboard:
  enable: false
  influxdb:
    host: localhost
    port: 50301
    use_udp: true
    udp_port: 50304
  ranklist:
    enable: false
    author: your_name
    commit: your_commit