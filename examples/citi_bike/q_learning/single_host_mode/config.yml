experiment_name: "TRAIN_MAXTIC5000_TRIP1_0.3_LR0.00005_COST0.5"
env:
  scenario: "bike"
  topology: "train"
  max_tick: 5000 # stop until the data steam end # 525600 tick per year
train:
  max_ep: 300 # max episode
  batch_num: 2
  batch_size: 512
  min_train_experience_num: 256 # when experience number is less than it, will not trigger train
  reward_shaping: 'tc'
  dqn:
    target_update_frequency: 5 # target network update frequency
    dropout_p: 0.0 # dropout parameter
    gamma: 0.0 # reward decay
    tau: 0.1 # soft update
    lr: 0.00005 # learning rate
  exploration:
    max_eps: 0.4 # max epsilon
    phase_split_point: 0.5 # exploration two phase split point
    first_phase_reduce_proportion: 0.8 # first phase reduce proportion of max_eps
  reward:
    shortage_factor: 1
    cost_factor: 0.5
  seed: 1024
test:
  max_ep: 5 # max episode
  seed: 2048
  topology: "test"
  max_tick: 2000
qnet:
  seed: 0
log:
  runner:
    enable: true
  agent:
    enable: false
  dqn:
    enable: false
    dropout_p: 0.95
  qnet:
    enable: false
  dashboard:
    enable: false
dashboard:
  enable: false
  influxdb:
    host: localhost
    port: 50301
    use_udp: true
    udp_port: 50304
  ranklist:
    enable: false
    author: your_name
    commit: your_commit